{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04edfa47-146d-4c1e-adcb-4fa522a88611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d940079f-3e3b-4ec5-8b38-1bfbe5163b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HOME\"] = os.path.join(os.getcwd(), \"model_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925b3243-007d-4d33-a548-cabb5167581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jui\\miniconda3\\envs\\grace_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e17afa-a628-4b98-b019-7948369115b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.getenv(\"MODEL_NAME\", \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c958554d-2ecd-4801-95e0-7c1e56691c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b364ed-2e62-4564-8c36-c4fa6348af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf33f59-0fce-4338-b759-38eed20af63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0a207e-df12-4cd5-a825-e8badf741ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "input_encoding = tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}], return_tensors=\"pt\", add_generation_prompt=True, return_dict=True,\n",
    ")\n",
    "\n",
    "preds = model.generate(\n",
    "    input_encoding[\"input_ids\"].to(device),\n",
    "    max_new_tokens=100, \n",
    "    # do_sample=True, \n",
    "    temperature=0.1, \n",
    "    top_p=0.95, \n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ").squeeze()\n",
    "answer = tokenizer.decode(preds[input_encoding[\"input_ids\"].shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae13a64-2f2a-463d-892c-92bdf1862934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151646, 151644,  13048, 151645, 151648,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6e7499-d507-4aec-b0e9-044f1b4cb602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_encoding[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775a2957-1634-44a1-bc79-c57899a09e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alright, the user just said \"Hi.\" That\\'s a friendly greeting. I should respond in a warm and welcoming manner.\\n\\nI want to make sure they feel comfortable asking anything. Maybe add an emoji to keep it light and approachable.\\n\\nLet me think of something simple but polite like, \"Hello! How can I assist you today?\" Yeah, that sounds good.\\n</think>\\n\\nHello! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459cf3ed-9502-4ec0-9ac2-423ff02b9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding = tokenizer(\n",
    "    [text],\n",
    "    # padding=\"longest\",\n",
    "    # max_length=20,\n",
    "    # truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "preds = model.generate(\n",
    "    input_encoding[\"input_ids\"].to(device), \n",
    "    max_new_tokens=100, \n",
    "    # do_sample=True, \n",
    "    temperature=0.1, \n",
    "    top_p=0.95, \n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ").squeeze()[len(input_encoding[\"input_ids\"]):]\n",
    "answer = tokenizer.decode(preds, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc126a4-aa7a-42c1-8554-30e50088a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, I\\'m trying to solve this problem: \"Given a positive integer n and an array A of length n. You have two arrays X and Y such that for each i from 1 to n-1, the sum of elements in X is equal to the sum of elements in Y.\" Wait, no, sorry, maybe it\\'s different.\\n\\nWait, let me read again:\\n\\n\"Given a positive integer n and an array A of length n. You have two arrays X and Y such that'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbcaf08-305c-45bc-b1e7-7f61e95c31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}], return_tensors=\"pt\", add_generation_prompt=True, tokenize=False\n",
    ")\n",
    "\n",
    "text_2 = tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi what are you doing\"}], return_tensors=\"pt\", add_generation_prompt=True, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c01154-8c3c-4572-b2f3-93a054204913",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding_1 = tokenizer(\n",
    "    [text_1], return_tensors=\"pt\", padding=\"max_length\", max_length=20, truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "747a4916-f34f-4734-813b-8013d4f7d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding_2 = tokenizer(\n",
    "    [text_2], return_tensors=\"pt\", padding=\"max_length\", max_length=20, truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00660600-4d99-4b72-afa7-c714835cb92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3753, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=input_encoding_1[\"input_ids\"].to(device), attention_mask=input_encoding_1[\"attention_mask\"].to(device), labels=input_encoding_2[\"input_ids\"].to(device)).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf6de7-97f9-4dd0-9b78-7b7b4ca17161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f298c9-8d10-421e-a08d-64082e10162b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169ad16-cf7f-45cf-bd27-53ff7f5822ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec634ce9-1216-490e-b330-91ca6d76c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "928de8c7-95d5-460f-900f-048f252f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi\"\n",
    "edit = \"Hi what are you doing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4191a0af-f664-4d5e-9c6c-badd769366c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [text]\n",
    "label = [edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fdb7f22-0d99-4ca2-96cb-40d9cff82ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67b42203-87fb-4b9c-b0c9-3dde2d1cdf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜>Hi what are you doing<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": text}, {\"role\": \"assistant\", \"content\": edit}], return_tensors=\"pt\", add_generation_prompt=False, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19d2303e-8594-420b-938f-02704981678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        conversation=[{\"role\": \"user\", \"content\": p}, {\"role\": \"assistant\", \"content\": l}], return_tensors=\"pt\", add_generation_prompt=False, tokenize=False\n",
    "    ) for p, l in zip(prompt, label)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f51f5349-06ee-421d-8746-5c07f1eb2e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜>Hi what are you doing<｜end▁of▁sentence｜>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6642ac51-7326-4a32-b5b0-167c80dc1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = tokenizer(list(prompt), return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4469ce7-3691-460f-8a2c-008eb3774e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prompt_toks = [int((i != tokenizer.pad_token_id).sum()) for i in prompt_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7708cba1-7d71-4d1c-87db-a9118db88174",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(full_prompt, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95b6bb4b-780c-4906-b6b7-c0e1615b8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[\"labels\"] = tokens[\"input_ids\"].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09ba4d1f-1390-49eb-bcb1-c7f20a8783e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prompt)):\n",
    "    tokens[\"labels\"][i][:num_prompt_toks[i]] = mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c705ed91-b991-49f9-a815-03f59aa5a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[\"labels\"][tokens[\"input_ids\"] == tokenizer.pad_token_id] = mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02dfbbcf-b661-4062-b3b1-24729f1e7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {f\"{k1}\" : v1.to(device) for k1, v1 in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01afb7d1-2052-4ebf-80b4-c917dfc3c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151646, 151646, 151644,  13048, 151645,  13048,   1128,    525,    498,\n",
       "            3730, 151643]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'),\n",
       " 'labels': tensor([[  -100,   -100, 151644,  13048, 151645,  13048,   1128,    525,    498,\n",
       "            3730,   -100]], device='cuda:0')}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c9c998e-1ad9-4a58-86be-542069081de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7990, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokens).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a35022d-5597-431c-b9b5-bc21c55c4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.generate(\n",
    "    tokens[\"input_ids\"], \n",
    "    max_new_tokens=100, \n",
    "    # do_sample=True, \n",
    "    # temperature=0.1, \n",
    "    # top_p=0.95, \n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ").squeeze()\n",
    "new_answer = tokenizer.decode(preds[tokens[\"input_ids\"].shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa005926-dace-4157-ac1c-661003708d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n</think>\\n\\nHi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. For comprehensive details about our models and products, we invite you to consult our official documentation.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3659aba8-a4a4-40d2-b216-6c21f7a9d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": text}], return_tensors=\"pt\", add_generation_prompt=True, tokenize=True, return_dict=True\n",
    ")\n",
    "preds = model.generate(\n",
    "    a[\"input_ids\"].to(device), \n",
    "    max_new_tokens=100, \n",
    "    # do_sample=True, \n",
    "    # temperature=0.1, \n",
    "    # top_p=0.95, \n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ").squeeze()\n",
    "new_answer = tokenizer.decode(preds[a[\"input_ids\"].shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af0d1659-8d99-443c-84f8-34fe2067d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alright, the user just said \"Hi.\" That\\'s a friendly greeting. I should respond in a welcoming manner to keep the conversation going.\\n\\nMaybe say something like, \"Hello! How can I assist you today?\" that seems helpful and open-ended.\\n</think>\\n\\nHello! How can I assist you today?'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8985cb-359c-49e7-a36a-20d5f210ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc92aa-7be0-4b62-b1cc-eb72968518fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1170bd-4ec3-48c2-91c4-380bd8bc3f10",
   "metadata": {},
   "source": [
    "## Chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd11771-a4e8-4da6-a6ec-41f4e75669b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}], return_tensors=\"pt\", add_generation_prompt=True, return_dict=False, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fab7c16-bbd6-44a2-8f8f-ec9cc21bbf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}], return_tensors=\"pt\", add_generation_prompt=False, return_dict=False, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3486df29-5f2d-4ae1-9a88-8cdefa206650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜>Hello, How are u?<｜end▁of▁sentence｜><｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}, {\"role\": \"assistant\", \"content\": \"Hello, How are u?\"}], return_tensors=\"pt\", add_generation_prompt=True, return_dict=False, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15916c7a-29a8-4316-a3c7-1a77a3ad43fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>Hi<｜Assistant｜>Hello, How are u?<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    conversation=[{\"role\": \"user\", \"content\": \"Hi\"}, {\"role\": \"assistant\", \"content\": \"Hello, How are u?\"}], return_tensors=\"pt\", add_generation_prompt=False, return_dict=False, tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2a809-0cd8-45f0-b26b-4d662536502f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
